{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6892add1-c69c-4d2c-8e2d-7e1b8c986379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, FunctionTransformer, LabelEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import SVR\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ddcbaa-431e-48c8-ab4a-4c4c9749f2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ames_original = pd.read_csv('Ames_HousePrice.csv', index_col=0)\n",
    "\n",
    "Ames = Ames_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a2ae5c-6ceb-405f-9f76-c746638d98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeted Feature Engineering\n",
    "Ames[\"GrLivArea_per_LotArea\"] = Ames[\"GrLivArea\"] / (Ames[\"LotArea\"] + 1)\n",
    "Ames[\"TotalSF\"] = Ames[\"GrLivArea\"] + Ames[\"TotalBsmtSF\"]\n",
    "Ames[\"HouseAge\"] = Ames[\"YrSold\"].astype(int) - Ames[\"YearBuilt\"].astype(int)\n",
    "Ames[\"HouseAgeSinceRemod\"] = Ames[\"YrSold\"].astype(int) - Ames[\"YearRemodAdd\"].astype(int)\n",
    "Ames[\"WasRemodeled\"] = Ames['YearRemodAdd'] > Ames[\"YearBuilt\"].astype(int)\n",
    "\n",
    "bath_cols = [\"FullBath\", \"HalfBath\", \"BsmtFullBath\", \"BsmtHalfBath\"]\n",
    "Ames[bath_cols] = Ames[bath_cols].fillna(0)\n",
    "# initialize only if not already set\n",
    "try:\n",
    "    half_weight\n",
    "except NameError:\n",
    "    half_weight = 0.5\n",
    "\n",
    "try:\n",
    "    b_weight\n",
    "except NameError:\n",
    "    b_weight = 1.0\n",
    "\n",
    "try:\n",
    "    b_weight_half\n",
    "except NameError:\n",
    "    b_weight_half = 0.5\n",
    "\n",
    "\n",
    "Ames['TotalBaths'] = Ames['FullBath'] + half_weight * Ames['HalfBath'] + b_weight * Ames['BsmtFullBath'] + b_weight_half * Ames['BsmtHalfBath']\n",
    "\n",
    "garage_cols = ['GarageArea', 'GarageCars']\n",
    "Ames[garage_cols] = Ames[garage_cols].fillna(0)\n",
    "\n",
    "basement_cols = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF']\n",
    "Ames[basement_cols] = Ames[basement_cols].fillna(0)\n",
    "\n",
    "Ames['MasVnrArea'] = Ames['MasVnrArea'].fillna(0)\n",
    "Ames['PoolArea'] = Ames['PoolArea'].fillna(0)\n",
    "\n",
    "# mapping dictionary\n",
    "style_map = {\n",
    "    \"1Story\": \"Ranch\",\n",
    "    \"SFoyer\": \"Ranch\",\n",
    "    \"SLvl\": \"Ranch\",\n",
    "    \"2Story\": \"Colonial\",\n",
    "    \"2.5Fin\": \"Colonial\",\n",
    "    \"2.5Unf\": \"Colonial\",\n",
    "    \"1.5Fin\": \"Other\",\n",
    "    \"1.5Unf\": \"Other\"\n",
    "}\n",
    "\n",
    "# apply to dataset\n",
    "Ames[\"RanchColonial\"] = Ames[\"HouseStyle\"].map(style_map)\n",
    "\n",
    "# Convert the below numeric features to categorical features\n",
    "Ames['MSSubClass'] = Ames['MSSubClass'].astype('object')\n",
    "Ames['YrSold'] = Ames['YrSold'].astype('object')\n",
    "Ames['MoSold'] = Ames['MoSold'].astype('object')\n",
    "Ames['WasRemodeled'] = Ames['WasRemodeled'].astype('object')\n",
    "\n",
    "\n",
    "# Add Interactions\n",
    "Ames['GrLivArea_x_Qual'] = Ames['GrLivArea'] * Ames['OverallQual']\n",
    "Ames['TotalSF_x_Qual'] = Ames['TotalSF'] * Ames['OverallQual']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6f0430-f67e-43e2-af34-c8d7636721fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c4ffe5c-7e68-451f-991e-d7487d3b9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ONE-CELL START: encoders + pipelines + CV helper ===\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Iterable, Optional, List, Dict, Tuple\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "\n",
    "# ----------------------------- Ordinal maps -----------------------------\n",
    "ORDINAL_ORDER: Dict[str, List[str]] = {\n",
    "    'Electrical': ['Mix', 'FuseP', 'FuseF', 'FuseA', 'SBrkr'],  # Electrical system\n",
    "    'LotShape': ['IR3', 'IR2', 'IR1', 'Reg'],  # General shape of property\n",
    "    'Utilities': ['ELO', 'NoSeWa', 'NoSewr', 'AllPub'],  # Type of utilities available\n",
    "    'LandSlope': ['Sev', 'Mod', 'Gtl'],  # Slope of property\n",
    "    'ExterQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],  # Evaluates the quality of the material on the exterior\n",
    "    'ExterCond': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],  # Evaluates the present condition of the material on the exterior\n",
    "    'BsmtQual': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],  # Height of the basement\n",
    "    'BsmtCond': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],  # General condition of the basement\n",
    "    'BsmtExposure': ['None', 'No', 'Mn', 'Av', 'Gd'],  # Walkout or garden level basement walls\n",
    "    'BsmtFinType1': ['None', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],  # Quality of basement finished area\n",
    "    'BsmtFinType2': ['None', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],  # Quality of second basement finished area\n",
    "    'HeatingQC': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],  # Heating quality and condition\n",
    "    'KitchenQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],  # Kitchen quality\n",
    "    'Functional': ['Sal', 'Sev', 'Maj2', 'Maj1', 'Mod', 'Min2', 'Min1', 'Typ'],  # Home functionality\n",
    "    'FireplaceQu': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],  # Fireplace quality\n",
    "    'GarageFinish': ['None', 'Unf', 'RFn', 'Fin'],  # Interior finish of the garage\n",
    "    'GarageQual': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],  # Garage quality\n",
    "    'GarageCond': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],  # Garage condition\n",
    "    'PavedDrive': ['N', 'P', 'Y'],  # Paved driveway\n",
    "    'PoolQC': ['None', 'Fa', 'TA', 'Gd', 'Ex'],  # Pool quality\n",
    "    'Fence': ['None', 'MnWw', 'GdWo', 'MnPrv', 'GdPrv']  # Fence quality\n",
    "}\n",
    "\n",
    "\n",
    "# --------------------- Utilities (metrics + helpers) --------------------\n",
    "def rmse(y_true, y_pred) -> float:\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "def _is_object_like(s: pd.Series) -> bool:\n",
    "    return s.dtype.kind in (\"O\", \"b\") or isinstance(s.dtype, CategoricalDtype)\n",
    "\n",
    "\n",
    "# --------------------------- Quantile capper ----------------------------\n",
    "class QuantileCapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lower_q: float = 0.01, upper_q: float = 0.99):\n",
    "        self.lower_q = lower_q\n",
    "        self.upper_q = upper_q\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        df = X if isinstance(X, pd.DataFrame) else pd.DataFrame(X)\n",
    "        self.feature_names_in_ = list(df.columns)\n",
    "        self.lower_ = df.quantile(self.lower_q)\n",
    "        self.upper_ = df.quantile(self.upper_q)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # >>> return DataFrame (not ndarray) so downstream ColumnTransformer can select by name\n",
    "        df = X if isinstance(X, pd.DataFrame) else pd.DataFrame(X, columns=self.feature_names_in_)\n",
    "        df = df.clip(self.lower_, self.upper_, axis=1)\n",
    "        return df   # <--- keep as DataFrame\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.asarray(self.feature_names_in_, dtype=object)\n",
    "\n",
    "\n",
    "# ------------------------- Preprocessor builder -------------------------\n",
    "def build_preprocessor(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    mode: str = \"linear\",  # 'linear' -> log/scale; 'tree' -> no log/scale on numerics\n",
    "    numeric_cap: Optional[Iterable[str]] = None,\n",
    "    lower_q: float = 0.01,\n",
    "    upper_q: float = 0.99,\n",
    "    log_cols: Optional[Iterable[str]] = None,          # (linear mode only)\n",
    "    scale_features: Optional[Iterable[str]] = None,    # (linear mode only)\n",
    "    zero_impute_cols: Optional[Iterable[str]] = None   # exact zeros for these numerics\n",
    ") -> ColumnTransformer:\n",
    "\n",
    "    if mode not in {\"linear\", \"tree\"}:\n",
    "        raise ValueError(\"mode must be 'linear' or 'tree'\")\n",
    "\n",
    "    # detect dtypes from engineered df\n",
    "    num_all = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    cat_all = [c for c in df.columns if _is_object_like(df[c])]\n",
    "\n",
    "    # partition categorical into ordinal vs nominal; Electrical is special\n",
    "    ordinal_explicit = [c for c in ORDINAL_ORDER.keys() if c in df.columns and c != \"Electrical\"]\n",
    "    nominal_all = [c for c in cat_all if c not in ORDINAL_ORDER.keys()]\n",
    "\n",
    "    # defaults (safe, you can override when calling)\n",
    "    zero_impute_cols = list(zero_impute_cols or [\"BsmtFullBath\", \"BsmtHalfBath\"])\n",
    "    zero_impute_cols = [c for c in zero_impute_cols if c in num_all]\n",
    "\n",
    "    # heavy-tail continuous candidates we’ll cap\n",
    "    default_cap = [\n",
    "        \"LotArea\",\"LotFrontage\",\"MasVnrArea\",\"TotalBsmtSF\",\n",
    "        \"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\",\n",
    "        \"1stFlrSF\",\"2ndFlrSF\",\"LowQualFinSF\",\"GrLivArea\",\n",
    "        \"GarageArea\",\"WoodDeckSF\",\"OpenPorchSF\",\"EnclosedPorch\",\n",
    "        \"3SsnPorch\",\"ScreenPorch\",\"PoolArea\",\"MiscVal\",\n",
    "        \"TotalSF\",\"GrLivArea_per_LotArea\",\n",
    "    ]\n",
    "    numeric_cap = set(numeric_cap or default_cap) & set(num_all)\n",
    "\n",
    "    if mode == \"linear\":\n",
    "        log_cols = set(log_cols or [\n",
    "            \"LotArea\", \"LotFrontage\", \"MasVnrArea\",\n",
    "            \"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"TotalBsmtSF\",\n",
    "            \"1stFlrSF\",\"2ndFlrSF\",\"LowQualFinSF\",\"GrLivArea\",\n",
    "            \"GarageArea\",\"WoodDeckSF\",\"OpenPorchSF\",\"EnclosedPorch\",\n",
    "            \"3SsnPorch\",\"ScreenPorch\",\"PoolArea\",\"MiscVal\",\"TotalSF\",\"GrLivArea_per_LotArea\",\n",
    "        ])\n",
    "        scale_features = set(scale_features or (\n",
    "            {\n",
    "                \"GrLivArea\",\"LotFrontage\",\"LotArea\",\"MasVnrArea\",\n",
    "                \"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"TotalBsmtSF\",\n",
    "                \"1stFlrSF\",\"2ndFlrSF\",\"LowQualFinSF\",\"GarageArea\",\n",
    "                \"WoodDeckSF\",\"OpenPorchSF\",\"EnclosedPorch\",\"3SsnPorch\",\n",
    "                \"ScreenPorch\",\"PoolArea\",\"MiscVal\",\"TotalSF\",\"GrLivArea_per_LotArea\",\n",
    "            }\n",
    "            | {\"BsmtFullBath\",\"BsmtHalfBath\",\"FullBath\",\"HalfBath\",\n",
    "               \"BedroomAbvGr\",\"KitchenAbvGr\",\"TotRmsAbvGrd\",\"Fireplaces\",\n",
    "               \"GarageCars\",\"TotalBaths\"}\n",
    "            | {\"OverallQual\",\"OverallCond\"}\n",
    "            | {\"HouseAge\",\"HouseAgeSinceRemod\",\"GarageAge\"}\n",
    "        ))\n",
    "    else:\n",
    "        log_cols = set()          # trees: no log on X\n",
    "        scale_features = set()    # trees: no scaling on X\n",
    "\n",
    "    # split numeric buckets\n",
    "    num_log_cap   = sorted((log_cols & numeric_cap) & set(num_all))\n",
    "    num_log_plain = sorted((log_cols - numeric_cap) & set(num_all))\n",
    "    num_cap_only  = sorted((numeric_cap - log_cols) & set(num_all))\n",
    "    # numerics to include without cap/log (linear mode: still scaled; tree: passthrough)\n",
    "    used_linear_buckets = set(num_log_cap) | set(num_log_plain) | set(num_cap_only)\n",
    "    num_plain = sorted([c for c in num_all if c not in used_linear_buckets])\n",
    "\n",
    "    # helper: per-branch imputer that sets exact zeros for selected count fields, mean otherwise\n",
    "    def make_imputer_for(cols: List[str]) -> ColumnTransformer:\n",
    "        zero_cols = [c for c in cols if c in zero_impute_cols]\n",
    "        mean_cols = [c for c in cols if c not in zero_impute_cols]\n",
    "        transformers = []\n",
    "        if zero_cols:\n",
    "            transformers.append((\"zero_imp\", SimpleImputer(strategy=\"constant\", fill_value=0), zero_cols))\n",
    "        if mean_cols:\n",
    "            transformers.append((\"mean_imp\", SimpleImputer(strategy=\"mean\"), mean_cols))\n",
    "        return ColumnTransformer(transformers=transformers, remainder=\"drop\", verbose_feature_names_out=False)\n",
    "\n",
    "    # numeric branch builders\n",
    "    def numeric_branch(cols: List[str], *, cap: bool, log: bool, scale: bool) -> Tuple[str, Pipeline, List[str]]:\n",
    "        if not cols:\n",
    "            return None\n",
    "        steps = []\n",
    "        if cap:\n",
    "            steps.append((\"cap\", QuantileCapper(lower_q=lower_q, upper_q=upper_q)))\n",
    "        steps.append((\"impute\", make_imputer_for(cols)))\n",
    "        if log:\n",
    "            steps.append((\"log1p\", FunctionTransformer(np.log1p, validate=False)))\n",
    "        if scale:\n",
    "            steps.append((\"scale\", StandardScaler()))\n",
    "        return (\"_tmp\", Pipeline(steps=steps), cols)\n",
    "\n",
    "    branches = []\n",
    "    # linear mode: scale=True; tree mode: scale=False; log only in linear buckets\n",
    "    branches += [numeric_branch(num_log_cap,   cap=True,  log=(mode==\"linear\"), scale=(mode==\"linear\"))] or []\n",
    "    branches += [numeric_branch(num_log_plain, cap=False, log=(mode==\"linear\"), scale=(mode==\"linear\"))] or []\n",
    "    branches += [numeric_branch(num_cap_only,  cap=True,  log=False,           scale=(mode==\"linear\"))] or []\n",
    "    branches += [numeric_branch(num_plain,     cap=False, log=False,           scale=(mode==\"linear\"))] or []\n",
    "    branches = [b for b in branches if b is not None]\n",
    "\n",
    "    # categorical: Electrical ordinal; others one-hot\n",
    "    electrical_pipe = Pipeline(steps=[\n",
    "        (\"impute_mf\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ordinal\",   OrdinalEncoder(categories=[ORDINAL_ORDER[\"Electrical\"]],\n",
    "                                     handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "    ]) if \"Electrical\" in df.columns else \"drop\"\n",
    "\n",
    "    if \"Electrical\" in nominal_all: nominal_all.remove(\"Electrical\")\n",
    "    if \"Electrical\" in ordinal_explicit: ordinal_explicit.remove(\"Electrical\")\n",
    "\n",
    "    ordinal_pipe = (\n",
    "        Pipeline(steps=[\n",
    "            (\"impute_none\", SimpleImputer(strategy=\"constant\", fill_value=\"None\")),\n",
    "            (\"ordinal\", OrdinalEncoder(categories=[ORDINAL_ORDER[c] for c in ordinal_explicit],\n",
    "                                       handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
    "        ])\n",
    "        if ordinal_explicit else \"drop\"\n",
    "    )\n",
    "\n",
    "    nominal_pipe = (\n",
    "        Pipeline(steps=[\n",
    "            (\"impute_none\", SimpleImputer(strategy=\"constant\", fill_value=\"None\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)),\n",
    "        ])\n",
    "        if nominal_all else \"drop\"\n",
    "    )\n",
    "\n",
    "    # assemble ColumnTransformer\n",
    "    transformers = []\n",
    "    if \"Electrical\" in df.columns:\n",
    "        transformers.append((\"elect\", electrical_pipe, [\"Electrical\"]))\n",
    "    # numeric branches (give each a friendly name)\n",
    "    name_map = [\"num_log_cap\",\"num_log_plain\",\"num_cap\",\"num_plain\"]\n",
    "    for i, b in enumerate(branches):\n",
    "        transformers.append((name_map[i], b[1], b[2]))\n",
    "    if ordinal_explicit:\n",
    "        transformers.append((\"ordinal\", ordinal_pipe, ordinal_explicit))\n",
    "    if nominal_all:\n",
    "        transformers.append((\"nominal\", nominal_pipe, nominal_all))\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=transformers,\n",
    "        remainder=\"drop\",\n",
    "        sparse_threshold=0.3,\n",
    "        verbose_feature_names_out=False\n",
    "    )\n",
    "    return pre\n",
    "\n",
    "\n",
    "# ------------------------- Pipeline factories --------------------------\n",
    "def make_linear_pipe(\n",
    "    df_schema: pd.DataFrame,\n",
    "    *,\n",
    "    model: str = \"ridge\",                     # 'ridge' | 'lasso' | 'enet' or pass an estimator instance via model_est\n",
    "    model_kwargs: Optional[dict] = None,\n",
    "    model_est: Optional[BaseEstimator] = None,\n",
    "    # preprocessing knobs (optional; use defaults if omitted)\n",
    "    numeric_cap: Optional[Iterable[str]] = None,\n",
    "    lower_q: float = 0.01,\n",
    "    upper_q: float = 0.99,\n",
    "    log_cols: Optional[Iterable[str]] = None,\n",
    "    scale_features: Optional[Iterable[str]] = None,\n",
    "    zero_impute_cols: Optional[Iterable[str]] = None,\n",
    ") -> TransformedTargetRegressor:\n",
    "    \"\"\"\n",
    "    Linear pipeline with fold-safe preprocessing + TTR(log1p). Returns a TTR wrapping the full Pipeline.\n",
    "    \"\"\"\n",
    "    if model_est is None:\n",
    "        model_kwargs = model_kwargs or {}\n",
    "        if isinstance(model, str):\n",
    "            key = model.lower()\n",
    "            if key == \"ridge\":\n",
    "                base = Ridge(max_iter=200_000, tol=1e-3, **model_kwargs)\n",
    "            elif key == \"lasso\":\n",
    "                base = Lasso(max_iter=200_000, tol=1e-3, **model_kwargs)\n",
    "            elif key == \"enet\":\n",
    "                base = ElasticNet(max_iter=200_000, tol=1e-3, **model_kwargs)\n",
    "            else:\n",
    "                raise ValueError(\"model must be 'ridge' | 'lasso' | 'enet' or pass model_est\")\n",
    "        else:\n",
    "            raise ValueError(\"If model_est is None, model must be a string key\")\n",
    "    else:\n",
    "        base = model_est\n",
    "\n",
    "    pre = build_preprocessor(\n",
    "        df_schema, mode=\"linear\",\n",
    "        numeric_cap=numeric_cap, lower_q=lower_q, upper_q=upper_q,\n",
    "        log_cols=log_cols, scale_features=scale_features,\n",
    "        zero_impute_cols=zero_impute_cols\n",
    "    )\n",
    "    pipe = Pipeline([(\"prep\", pre), (\"reg\", base)])\n",
    "    return TransformedTargetRegressor(\n",
    "        regressor=pipe,\n",
    "        func=np.log1p, inverse_func=np.expm1\n",
    "    )\n",
    "\n",
    "\n",
    "def make_histgb_pipe(\n",
    "    df_schema: pd.DataFrame,\n",
    "    *,\n",
    "    hgb_kwargs: Optional[dict] = None,\n",
    "    numeric_cap: Optional[Iterable[str]] = None,\n",
    "    lower_q: float = 0.01,\n",
    "    upper_q: float = 0.99,\n",
    "    zero_impute_cols: Optional[Iterable[str]] = None,\n",
    ") -> Pipeline:\n",
    "    \"\"\"\n",
    "    Tree pipeline: cap + impute + encoders; NO log/scale on features. Uses HistGB (fast, strong).\n",
    "    \"\"\"\n",
    "    hgb_kwargs = hgb_kwargs or {\"random_state\": 42}\n",
    "    pre = build_preprocessor(\n",
    "        df_schema, mode=\"tree\",\n",
    "        numeric_cap=numeric_cap, lower_q=lower_q, upper_q=upper_q,\n",
    "        log_cols=[], scale_features=[],\n",
    "        zero_impute_cols=zero_impute_cols\n",
    "    )\n",
    "    return Pipeline([(\"prep\", pre), (\"reg\", HistGradientBoostingRegressor(**hgb_kwargs))])\n",
    "\n",
    "\n",
    "# ---------------------- Quick CV leaderboard helper --------------------\n",
    "def cv_eval_models(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series | np.ndarray,\n",
    "    models: List[Tuple[str, BaseEstimator]],\n",
    "    *,\n",
    "    cv: int = 5,\n",
    "    random_state: int = 42,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Works with full pipelines (including TTR). Computes OOF RMSE/R2 in $-space.\n",
    "    \"\"\"\n",
    "    y_np = y.to_numpy() if hasattr(y, \"to_numpy\") else np.asarray(y)\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "    rows = []\n",
    "\n",
    "    for name, est in models:\n",
    "        fold_rmses, oof = [], np.zeros(len(y_np), dtype=float)\n",
    "        for tr, va in kf.split(X):\n",
    "            X_tr, X_va = X.iloc[tr], X.iloc[va]\n",
    "            y_tr, y_va = y_np[tr], y_np[va]\n",
    "            est.fit(X_tr, y_tr)\n",
    "            pred = est.predict(X_va)\n",
    "            fold_rmses.append(rmse(y_va, pred))\n",
    "            oof[va] = pred\n",
    "\n",
    "        # full-fit R2\n",
    "        est.fit(X, y_np)\n",
    "        y_full = est.predict(X)\n",
    "\n",
    "        rows.append({\n",
    "            \"model\": name,\n",
    "            \"cv_rmse_mean\": float(np.mean(fold_rmses)),\n",
    "            \"cv_rmse_std\":  float(np.std(fold_rmses, ddof=0)),\n",
    "            \"r2_cv\":  float(r2_score(y_np, oof)),\n",
    "            \"r2_full\": float(r2_score(y_np, y_full)),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"cv_rmse_mean\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ------------------------------- Demo use -------------------------------\n",
    "# Example usage after you build your engineered dataframe X_fe and target y:\n",
    "# ridge_pipe = make_linear_pipe(X_fe, model=\"ridge\", model_kwargs={\"alpha\": 12.0},\n",
    "#                               zero_impute_cols=[\"BsmtFullBath\",\"BsmtHalfBath\"])\n",
    "# enet_pipe  = make_linear_pipe(X_fe, model=\"enet\",  model_kwargs={\"alpha\": 0.01, \"l1_ratio\": 0.3})\n",
    "# hgb_pipe   = make_histgb_pipe(X_fe, hgb_kwargs={\"random_state\":42, \"max_depth\": None, \"max_iter\": 800})\n",
    "#\n",
    "# models = [\n",
    "#     (\"Ridge (log+cap+scale)\", ridge_pipe),\n",
    "#     (\"ElasticNet (log+cap+scale)\", enet_pipe),\n",
    "#     (\"HistGB (cap only)\", hgb_pipe),\n",
    "# ]\n",
    "# print(cv_eval_models(X=X_fe, y=y, models=models, cv=5))\n",
    "# === ONE-CELL END ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28707cec-0cbf-4f78-a3f1-f3c34d9a870a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        model  cv_rmse_mean  cv_rmse_std     r2_cv   r2_full\n",
      "0       Ridge (log+cap+scale)  21746.436632  4853.403186  0.911779  0.939947\n",
      "1           HistGB (cap only)  23873.922040  4311.943126  0.895414  0.999785\n",
      "2  ElasticNet (log+cap+scale)  24094.708544  5166.936348  0.892092  0.909806\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "ridge_pipe = make_linear_pipe(X_fe, model=\"ridge\", model_kwargs={\"alpha\": 12.0},\n",
    "                              zero_impute_cols=[\"BsmtFullBath\",\"BsmtHalfBath\"])\n",
    "enet_pipe  = make_linear_pipe(X_fe, model=\"enet\",  model_kwargs={\"alpha\": 0.01, \"l1_ratio\": 0.3})\n",
    "hgb_pipe   = make_histgb_pipe(X_fe, hgb_kwargs={\"random_state\":42, \"max_iter\":800})\n",
    "\n",
    "print(cv_eval_models(X=X_fe, y=y, models=[\n",
    "    (\"Ridge (log+cap+scale)\", ridge_pipe),\n",
    "    (\"ElasticNet (log+cap+scale)\", enet_pipe),\n",
    "    (\"HistGB (cap only)\", hgb_pipe),\n",
    "], cv=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
